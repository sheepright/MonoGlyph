seed: 2
model: mx

# Decomposition rule
decomposition:
primals:

max_iter: 800000    # ìµœëŒ€ iteration ìˆ˜
g_lr: 2e-4
d_lr: 1e-3
ac_lr: 2e-4
adam_betas: [0.0, 0.9]

trainer:
  resume:            # (ë¹„ì›Œì§): ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° resume í•˜ì§€ ì•ŠìŒ
  force_resume: False
  work_dir: ./result/mx      # ê²°ê³¼ ì €ì¥ ìœ„ì¹˜ â†’ ì—¬ê¸°ì— ë¡œê·¸, ì´ë¯¸ì§€, ëª¨ë¸ ê°€ì¤‘ì¹˜ ë“± ì €ì¥ë¨

  # Losses
  pixel_loss_type: l1        # í”½ì…€ ì†ì‹¤ì€ L1 Loss ì‚¬ìš©
  pixel_w: 0.1               # í”½ì…€ ì†ì‹¤ ê°€ì¤‘ì¹˜
  gan_w: 1.0                 # GAN ì†ì‹¤ ê°€ì¤‘ì¹˜
  fm_layers: all             # feature matchingì— ëª¨ë“  layer ì‚¬ìš©
  fm_w: 1.0
  ac_w: 1.0                  # auxiliary classifier ì†ì‹¤ ê°€ì¤‘ì¹˜
  ac_gen_w: 1.0
  ac_cross_w: 0.0
  indp_exp_w: 1.0            # expert ë…ë¦½ì„± ì†ì‹¤
  indp_fact_w: 1.0

  # Display
  save: all-last             # ì €ì¥ ë°©ì‹: ì „ì²´ + ë§ˆì§€ë§‰
  print_freq: 1000           # ë¡œê·¸ ì¶œë ¥ ë¹ˆë„ (iter ë‹¨ìœ„)
  val_freq: 10000            # validation ì£¼ê¸°
  save_freq: 50000           # ğŸ”¥ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì£¼ê¸° (ì—¬ê¸°ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„± ìˆìŒ) + defult = 50000
  tb_freq: 100               # tensorboard ì£¼ê¸°

gen:
  n_experts: 6
  n_emb: 2
  
dset:
  loader:
    batch_size: 8
    num_workers: 16
  train:
    n_in_s: 3
    n_in_c: 3
